{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eDSL B: Dataframes for big-data processing\n",
    "#### Lef Ioannidis (@elefthei) : Investment Engineer, Bridgewater Associates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PeriodSeries eDSL allows us to do statistics with a high-degree of safety as well as provenance. \n",
    "\n",
    "But what if we want to operate on hundreds of PeriodSeries, while maintaining both safety and provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.collection.immutable.HashMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type Symbol = String\n",
    "val stocks: HashMap[Symbol, Double] = HashMap(\n",
    "    \"AAPL\" -> 180.26,\n",
    "    \"ABC\" -> 200.00,\n",
    "    \"VIX\" -> 48, \n",
    "    \"SPY\" -> 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object StockType extends Enumeration {\n",
    "  type Inner = Value\n",
    "  // Can be one of the following\n",
    "  val Index,Technology,Finance = Value\n",
    "  def fromString(s: String): Value = s match {\n",
    "    case \"AAPL\" => Technology\n",
    "    case \"ABC\" => Technology\n",
    "    case \"VIX\" => Index\n",
    "    case \"SPY\" => Index\n",
    "  }\n",
    "}\n",
    "type StockType = StockType.Inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy, map etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.groupBy { case (k,v) => StockType.fromString(k) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.mapValues(_ * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins\n",
    "### We also want to be able to join Maps a-la SQL join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit class JoinableMaps[F, U](left: HashMap[F, U]) {\n",
    "    def join[V](right: HashMap[F, V]): HashMap[F, (U, V)] =\n",
    "     new HashMap[F, (U, V)]() ++ left.keySet.union(right.keySet)\n",
    "        .map(k =>\n",
    "          (k, (left.getOrElse(k, throw new IllegalArgumentException(s\"Left field $k not found\")),\n",
    "            right.getOrElse(k, throw new IllegalArgumentException(s\"Right field $k not found\")))))\n",
    "        .toMap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val costs = HashMap(\n",
    "    \"AAPL\" -> 500e6,\n",
    "    \"ABC\" -> 200e6)\n",
    "\n",
    "val earnings = HashMap(\n",
    "    \"AAPL\" -> 800e6,\n",
    "    \"ABC\" -> 500e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val returns = earnings.join(costs).mapValues { case (left, right) => left - right }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is by-and-large, the feel of our dataframe language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "1. General enough to do everything.\n",
    "2. Execution; maybe on local machine maybe on a Map-reduce cluster.\n",
    "3. Provenance; we saw automatic provenance, how about manual?\n",
    "4. Lazyness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same trick\n",
    "### Reify higher-order syntax & interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "LMap[F, U] = \n",
    "  Single(inner: HashMap[F, U])\n",
    "   | Provenance(description: String, fa: LMap[F, U])\n",
    "   | Map[G,B](fa: LMap[F, U], f: (F, U) => (G, B))\n",
    "   | FlatMap[G,B](fa: LMap[F, U], f: (F, U) => LMap[G, B])\n",
    "   | Fold[G,B](fa: LMap[F, U], z: LMap[G, B], f: LMap[G, B] => (F, U) => LMap[G, B])\n",
    "   | Join[B,C](l: LMap[F, B], r: LMap[F, C])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  sealed trait LMap[F, U] extends Product with Serializable {\n",
    "    // Implement these\n",
    "    def run: HashMap[F, U]\n",
    "    def map[H, I](f: (F, U) => (H, I)): LMap[H, I]\n",
    "    def flatMap[H, I](f: (F, U) => LMap[H, I]): LMap[H, I]\n",
    "    def foldLeft[G, B](z: LMap[G, B], f: LMap[G, B] => (F, U) => LMap[G, B]): LMap[G, B]\n",
    "    def join[C](r: LMap[F, C]): LMap[F, (U, C)]\n",
    "    def trace(): String // for provenance\n",
    "\n",
    "    // Derived functions\n",
    "    def empty[H, I](): LMap[H, I] = HashMap[H, I]().reify\n",
    "\n",
    "    def collect[H, I](f: (F, U) PartialFunction (H, I)): LMap[H, I] =\n",
    "      flatMap((k: F, v: U) => f.lift(k, v) match {\n",
    "        case None => empty[H, I]()\n",
    "        case Some(out) => LMap(out._1 -> out._2)\n",
    "      })\n",
    "\n",
    "    def filter(f: (F, U) => Boolean): LMap[F, U] =\n",
    "      collect { case (k, v) if f(k, v) => (k, v) }\n",
    "\n",
    "    // Add provenance interleaved with ops\n",
    "    def provenance(op: String): LMap[F, U] =\n",
    "      Provenance(op, this)\n",
    "\n",
    "    def groupBy[G](f: F => G): LMap[G, LMap[F, U]] =\n",
    "      map { case (k, _) => (f(k), this) } // HashMap will drop duplicates\n",
    "\n",
    "    // Z can be anything, including a primitive type. Evaluate\n",
    "    def foldLeft[Z](z: Z, f: (Z, (F, U)) => Z): Z =\n",
    "      run.foldLeft(z)(f)\n",
    "\n",
    "    def foldRight[Z](z: Z, f: ((F, U), Z) => Z): Z =\n",
    "      run.foldRight(z)(f)\n",
    "  }\n",
    "\n",
    "  // Companion object\n",
    "  object LMap {\n",
    "    def apply[H, I](args: (H, I)*): LMap[H, I] =\n",
    "      HashMap[H, I](args: _*).reify\n",
    "  }\n",
    "\n",
    "  // Reified Map\n",
    "  final case class Map[F, G, U, B](fa: LMap[F, U], f: (F, U) => (G, B)) extends LMap[G, B] {\n",
    "    override def run: HashMap[G, B] = fa.run.map { case (k, v) => f(k, v) }\n",
    "\n",
    "    // Optimization!\n",
    "    override def map[H, I](g: (G, B) => (H, I)): LMap[H, I] =\n",
    "      Map(fa, (a: F, b: U) => {\n",
    "        val (x, y) = f(a, b) // Compose f . g\n",
    "        g(x, y)\n",
    "      })\n",
    "\n",
    "    override def join[V](r: LMap[G, V]): LMap[G, (B, V)] =\n",
    "      Join(this, r)\n",
    "\n",
    "    override def flatMap[H, I](g: (G, B) => LMap[H, I]): LMap[H, I] =\n",
    "      FlatMap(this, g)\n",
    "\n",
    "    override def foldLeft[H, I](z: LMap[H, I], f: LMap[H, I] => (G, B) => LMap[H, I]): LMap[H, I] =\n",
    "      Fold(this, z, f)\n",
    "\n",
    "    // Only print provenance\n",
    "    override def trace(): String = fa.trace\n",
    "  }\n",
    "\n",
    "  // Reified FlatMap\n",
    "  final case class FlatMap[F, U, G, B](fa: LMap[F, U], f: (F, U) => LMap[G, B]) extends LMap[G, B] {\n",
    "    override def run: HashMap[G, B] = fa.run.flatMap { case (k, v) => f(k, v).run.toIterable }\n",
    "\n",
    "    override def map[H, I](g: (G, B) => (H, I)): LMap[H, I] =\n",
    "      Map(this, g)\n",
    "\n",
    "    override def join[V](r: LMap[G, V]): LMap[G, (B, V)] =\n",
    "      Join(this, r)\n",
    "\n",
    "    // Optimization\n",
    "    override def flatMap[H, I](g: (G, B) => LMap[H, I]): LMap[H, I] =\n",
    "      FlatMap(fa, (k: F, v: U) => f(k, v).flatMap(g))\n",
    "\n",
    "    override def foldLeft[H, I](z: LMap[H, I], f: LMap[H, I] => (G, B) => LMap[H, I]): LMap[H, I] =\n",
    "      Fold(this, z, f)\n",
    "\n",
    "    // Only print provenance\n",
    "    override def trace(): String = fa.trace\n",
    "  }\n",
    "\n",
    "  // Reified Fold\n",
    "  final case class Fold[F, U, G, B](fa: LMap[F, U], z: LMap[G, B], f: LMap[G, B] => (F, U) => LMap[G, B]) extends LMap[G, B] {\n",
    "    override def run: HashMap[G, B] = fa.run.foldLeft(z) { case (h, (k, v)) => f(h)(k, v) }.run\n",
    "\n",
    "    override def map[H, I](g: (G, B) => (H, I)): LMap[H, I] =\n",
    "      Map(this, g)\n",
    "\n",
    "    override def join[V](r: LMap[G, V]): LMap[G, (B, V)] =\n",
    "      Join(this, r)\n",
    "\n",
    "    override def flatMap[H, I](g: (G, B) => LMap[H, I]): LMap[H, I] =\n",
    "      FlatMap(this, g)\n",
    "\n",
    "    override def foldLeft[H, I](s: LMap[H, I], g: LMap[H, I] => (G, B) => LMap[H, I]): LMap[H, I] =\n",
    "      Fold(this, s, g)\n",
    "\n",
    "    // Only print provenance\n",
    "    override def trace(): String = fa.trace\n",
    "  }\n",
    "\n",
    "  // Join expressions\n",
    "  final case class Join[F, B, C](l: LMap[F, B], r: LMap[F, C]) extends LMap[F, (B, C)] {\n",
    "    override def run: HashMap[F, (B, C)] = {\n",
    "      // Real join implementation, pretty inefficient but succinct\n",
    "      val left: HashMap[F, B] = l.run\n",
    "      val right: HashMap[F, C] = r.run\n",
    "\n",
    "      // Annoying way to initialize a HashMap\n",
    "      new HashMap[F, (B, C)]() ++ left.keySet.union(right.keySet)\n",
    "        .map(k =>\n",
    "          (k, (left.getOrElse(k, throw new IllegalArgumentException(s\"Left field $k not found\")),\n",
    "            right.getOrElse(k, throw new IllegalArgumentException(s\"Right field $k not found\")))))\n",
    "        .toMap\n",
    "    }\n",
    "\n",
    "    override def map[H, I](g: (F, (B, C)) => (H, I)): LMap[H, I] =\n",
    "      Map(this, g)\n",
    "\n",
    "    override def join[D](r: LMap[F, D]): LMap[F, ((B, C), D)] =\n",
    "      Join(this, r)\n",
    "\n",
    "    override def flatMap[H, I](g: (F, (B, C)) => LMap[H, I]): LMap[H, I] =\n",
    "      FlatMap(this, g)\n",
    "\n",
    "    override def foldLeft[H, I](z: LMap[H, I], f: LMap[H, I] => (F, (B, C)) => LMap[H, I]): LMap[H, I] =\n",
    "      Fold(this, z, f)\n",
    "\n",
    "    // Print provenance\n",
    "    override def trace(): String = \"JOIN {\\n\" ++ l.trace() ++ \",\\n\" ++ r.trace() ++ \"}\\n\"\n",
    "  }\n",
    "\n",
    "  // Interleave provenance with computation\n",
    "  final case class Provenance[F, U](op: String, fa: LMap[F, U]) extends LMap[F, U] {\n",
    "    override def run: HashMap[F, U] = fa.run\n",
    "    override def map[H, I](f: (F, U) => (H, I)): LMap[H, I] =\n",
    "      Map(this, f)\n",
    "\n",
    "    override def flatMap[H, I](f: (F, U) => LMap[H, I]): LMap[H, I] =\n",
    "      FlatMap(this, f)\n",
    "\n",
    "    override def foldLeft[G, B](z: LMap[G, B], f: LMap[G, B] => (F, U) => LMap[G, B]): LMap[G, B] =\n",
    "      Provenance(op, fa.foldLeft(z, f))\n",
    "\n",
    "    override def join[C](r: LMap[F, C]): LMap[F, (U, C)] =\n",
    "      Provenance(op, fa.join(r))\n",
    "\n",
    "    override def trace(): String = fa.trace() ++ op ++ \"\\n\" ++ fa.run.toString() ++ \"\\n\\n\"\n",
    "  }\n",
    "\n",
    "  // Algebra entry point\n",
    "  final case class Single[F, B](in: HashMap[F, B]) extends LMap[F, B] {\n",
    "    override def run: HashMap[F, B] = in\n",
    "\n",
    "    override def map[H, I](g: (F, B) => (H, I)): LMap[H, I] =\n",
    "      Map(this, g)\n",
    "\n",
    "    // If I had my trusty MultiJoin3 here it would be piece of cake\n",
    "    override def join[C](r: LMap[F, C]): LMap[F, (B, C)] =\n",
    "      Join(this, r)\n",
    "\n",
    "    override def flatMap[H, I](g: (F, B) => LMap[H, I]): LMap[H, I] =\n",
    "      FlatMap(this, g)\n",
    "\n",
    "    override def foldLeft[H, I](z: LMap[H, I], f: LMap[H, I] => (F, B) => LMap[H, I]): LMap[H, I] =\n",
    "      Fold(this, z, f)\n",
    "\n",
    "    override def trace(): String = \"\"\n",
    "  }\n",
    "\n",
    "  // Lift HashMap to Lazy Map\n",
    "  implicit class LazyOps[F, U](h: HashMap[F, U]) {\n",
    "    def reify: LMap[F, U] = Single(h)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach to provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val lazystocks = \n",
    "    stocks.reify\n",
    "      .provenance(\"Initial stock valuation\")\n",
    "      .map { case (k, v) => (k, 2 * v) }\n",
    "      .flatMap { case (k, v) => LMap((k, \"up\") -> -v, (k, \"down\") -> v) }\n",
    "      .provenance(\"Doubled & Showed directionality\")\n",
    "  lazystocks.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val finalstocks = \n",
    "    lazystocks\n",
    "      .collect { case (k, v) if v < 0 => (k._1, v / 2) }\n",
    "      .map { case (k, v) => (k, -v) }\n",
    "      .provenance(\"Return to the initial portfolio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalstocks.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provenance; documentation interleaved with computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalstocks.trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "### The eDSL gives us an object representation of logic. Can optimize, can codegen or even generate an Apache Spark Context.\n",
    "## Related: [twitter/scalding](https://github.com/twitter/scalding)\n",
    "\n",
    "## Questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
